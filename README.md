# Qsen
这是一个智能平台的初步构想

    最近一段时间看到一个语音助手帖子，说iphone的siri这么难用为什么还会被一直研发，谷歌的GoogleAssistan已经在appstore上架了。我想了下就立即回复苹果不可能放弃siri，因为语音助手太重要了。因为语音助手大家可能只能想到的只是打个电话，放首歌，搜索下问题，但是如果我说是“智能语音助手”大家会怎么想！！！
    大家可以构想下智能语音助手，我们只需要告诉它“我要从北京去上海，帮我订张早晨8点去上海的高铁票，晚上要住在离东方明珠最近的星级酒店”，只能助手就帮助我完成了行程的安排。这样我们是不是省去了很多事情，智能助手相当于秘书和助手帮助我们把不关心的一些简单事物完成甚至比人做的更好，提醒你是不是在上海需要一个“专职司机”，一家合口的餐厅等等。

 智能化备忘录（启森篇）
    现在语音助手只能完成一个简单操作，还未达到真正智能。当技术成熟并普及后，语音智能助手会像人一样完成一件事件A，对多个`事件A,B,C`进行编排关联成一个"任务1"。甚至对"任务1,2,3"继续进行编排这样无限递归编排逻辑关系等等。(因为声音是人类自言语言沟通的重要介质，这决定我们先对语音的智能化进行一些构想「至少智能设备植入普及前，语音智能还是比较理想的方式)
跨职能流程图（水平）.png​
   
    智能语音助手的使命决定了它不能平凡和孤独，所以设定他需要有如下特性：时刻职守，平台化，人性化，触发响应。

智能引擎像守护进程
因为智能助手随时等候命令，不能跳出程序一旦跳出就是失职。支持实时对讲，也就是锁定语音输入的用户，锁定用户操作程序并对程序持续操作。相当于现在现在主流多任务切换。实时对讲是智能引擎一直前台接受输入，根据输入执行指定操作，还有一部分智能平台无法完成的就需要切换到应用内操作，当然智能平台也能帮你接管程序自动操作。


智能引擎的插件化平台化
智能平台可以对接各种app，通过对接智能平台把自然语言转化为对应app的内部操作指令。例如：简单的应用内发送消息，发送图片。或者一个语音指令让汽车把你送到机场后再去接孩子下学。真正做到目标既任务。

人性化
逻辑关系分析，人性化，纠错性是核心部分能体现“智能助手”和“语音助手”区别。把一些不同行业的名词或习惯性的东西自动或手动录入，自动纠正，更加逻辑合理化。例如：允许智能引擎通过你的社会关系网，当你累了告诉他你要回家自动通知家人或司机接你，并告诉他们你的位置。你困了了可以自动订购你喜爱的半岛咖啡。

触发式响应
触发响应是为了弥补人有意识或无意识的失误。包括事件提醒，操作警告，危险强制执行。例如：火车晚点我要睡觉，智能系统自动监听火车的广播消息，一旦火车到站检票立即通知我。

    当然要完成上面的的目标我们还需要提升语音的识别率，逻辑判断，这些都需要大量的数据，机器学习和不断的实践。最困难的步骤还是平台化，要大量的实用程序对“智能助手”开放接口。在这个互联网争霸的时代大家都在不断建立自己的壁垒实现起来太困难了
 



